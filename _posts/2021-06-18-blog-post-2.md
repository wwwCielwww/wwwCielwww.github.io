---
title: 'Study Notes: GNN Part (II) ðŸŒ² Message Passing Networks'
date: 2021-06-18
permalink: /posts/2021/06/gnn-2/
categories:
  - Computer Science
tags:
  - GNN
---

Introduce **neighborhood aggregation** / **message passing** scheme that is commonly applied to generalize the convolution operator to irregular domains. Illustrate the `MessagePassing` base class in `PyG`, and provide implementation of the *GCN layer* and the *edge convolution*.

Credit ðŸ”¥ PyTorch Geometric (`PyG`) provides a very detailed [documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#creating-message-passing-networks) for creating message passing networks via the base class `MessagePassing`.

![](/assets/img/banner-2.jpg)

## Message Passing Scheme

*Pipeline*:$\quad$Transform features of adjacent nodes $\to$ Aggregate $\to$ Update the central node

To put things mathematically, denote node features of node $i$ in layer $(k-1)$ by $\mathbf{e}_{j, i}\in\mathbb{R}^D$ and (optional) edge features from node $j$ to node $i$ by $\mathbf{e}_{j, i}\in\mathbb{R}^D$. Message passing GNNs can be described as

$$
\mathbf{x}_i^{(k)} = \gamma^{(k)} \left( \mathbf{x}_i^{(k-1)}, \square_{j \in \mathcal{N}(i)} \, \phi^{(k)}\left(\mathbf{x}_i^{(k-1)}, \mathbf{x}_j^{(k-1)},\mathbf{e}_{j,i}\right) \right),
$$

where $\square$ denotes a differentiable, permutation invariant function, e.g., sum, mean or max, and $\gamma$ (for update) and $\phi$ (for message construction) denote differentiable functions such as MLPs.

## The `MessagePassing` Base Class

The `MessagePassing` class in `PyG` helps in creating message passing GNNs by automatically taking care of message propagation. The key methods (which should be re-implemented by users) are `message()` and `update()`. Aggregation scheme to use can be defined when initializing an instance of the class, e.g., `MessagePassing(aggr="add", flow="source_to_target", node_dim=-2)`. The method `propagate()` makes the initial call to start propagating messages.

**Remark** $\quad$`propagate()` checks if the argument `edge_index` is of the `SparseTensor` type and if the `message_and_aggregate()` method has been implemented in the derived class. If yes, then the more time efficient `message_and_aggregate()` is called instead of `message()`, `aggregate()` and `update()` sequentially. `

## Implementing the GCN Layer

## Implementing the Edge Convolution

