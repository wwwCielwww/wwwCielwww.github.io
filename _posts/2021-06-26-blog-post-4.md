---
title: 'Study Notes: GNN Part (IV) ðŸŒ² Node & Edge Prediction'
date: 2021-06-26
permalink: /posts/2021/06/gnn-4/
categories:
  - Computer Science
tags:
  - GNN
---

## Node Classification - A Revision

Following from the last post of the series, for node classification task, we can use other convolutional layers (other than `GCNConv` & `GATConv`, documentation available [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers)) or a different design of the network (e.g., number of layers, number of filters). An example of GNN using `SAGEConv` with number of filters for each layer specified by the parameter `hidden_channels` is provided below.

```python
import torch.nn.functional as F
from torch.nn import ReLU, Linear, Module
from torch_geometric.nn import SAGEConv, Sequential

class GraphSAGE(Module):
    def __init__(self, num_features, hidden_channels, num_classes):
        super().__init__()
        channels = [num_features] + hidden_channels
        convs = []
        for i in range(len(channels) - 1):
            convs.append((
                SAGEConv(channels[i], channels[i + 1]),
                "x, edge_index -> x"
            ))
            convs.append(ReLU(inplace=True))
        self.convs = Sequential("x, edge_index", convs)
        self.linear = Linear(channels[-1], num_classes)
        
    def forward(self, x, edge_index):
        x = self.convs(x, edge_index)
        x = F.dropout(x, p=0.5)
        return self.linear(x)
```

Notice that the `Sequential` here is an extension of the `torch.nn.Sequential` container in order to define a sequential GNN model. Since GNN operators take in multiple input arguments, `torch_geometric.nn.Sequential` expects both global input arguments, and function header definitions of individual operators. Here, where `'x, edge_index'` defines the input arguments of `convs`, and `'x, edge_index -> x'` defines the function header, *i.e.* input arguments *and* return types, of `SAGEConv`. For its more of its usage, see the [doc](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.sequential.Sequential).

## Edge Prediction

- Task: predict if there exists an edge between a pair of nodes
- `edge_index` obtained from the dataset concerned includes all the possible pairs of nodes with an edge between them. To train a model, we also need some node pairs without an edge. 
- As a common practice, the data will be divided into those for training, evaluating and testing.

Fortunately, the function `train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1)` in `PyG` can help sample node pairs without an edge and divide the data (which includes both node pairs with and without an edge). After applying the function, our data would have the attributes `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`, `val_neg_edge_index`, `test_pos_edge_index` and `test_neg_edge_index`, substituting the original `edge_index`.

```python
from torch_geometric.utils import negative_sampling
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures()
from torch_geometric.utils import train_test_split_edges

dataset = Planetoid('dataset', 'Cora', transform=NormalizeFeatures())
data = dataset[0]

# we're no longer interested in these
data.train_mask = data.val_mask = data.test_mask = data.y = None 

print(data.edge_index.shape)
# torch.Size([2, 10556])

data = train_test_split_edges(data)

for key in data.keys:
    print(key, getattr(data, key).shape)
```

| `x`          | `train_pos_edge_index` | `train_neg_adj_mask` | `val_pos_edge_index` | `val_neg_edge_index` | `test_pos_edge_index` | `test_neg_edge_index` |
| ------------ | ---------------------- | -------------------- | -------------------- | -------------------- | --------------------- | --------------------- |
| [2708, 1433] | [2, 8976]              | [2708, 2708]         | [2, 263]             | [2, 263]             | [2, 527]              | [2, 527]              |

Notice that `train_neg_adj_mask` is distinctly different from the other edge indices in terms of the shape, also that positive and negative samples of the same divided dataset have the same number of edges. 

For `Cora`, the graph is undirected, which means that the `edge_index` includes ($10556/2$) edges twice. Each two edges only differ in direction. When training a model, we need to consider information from both sides of an edge, which is not the case when evaluating or testing $\to8976/2+263+527=10556/2$.

```
import torch
from torch.nn import ReLU, Module
from torch_geometric.nn import GCNConv, Sequential

class Net(Module):
    def __init__(self, channels):
        super().__init__()
        convs = []
        for i in range(len(channels) - 1):
            convs.append((
                GCNConv(channels[i], channels[i + 1]),
                "x, edge_index -> x"
            ))
            convs.append(ReLU(inplace=True))
        self.convs = Sequential("x, edge_index", convs)

    def encode(self, x, edge_index):
        return self.convs(x, edge_index)

    def decode(self, x, pos_edge_index, neg_edge_index):
        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)
        return (x[edge_index[0]] * x[edge_index[1]]).sum(dim=-1)

    def decode_all(self, x):
        prob_adj = x @ x.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()
```



