---
title: 'Martingale'
date: 2021-05-23
permalink: /posts/2021/05/martingale/
categories:
  - Mathematics
tags:
  - Probability Theory
---

Introduce Martingale in probability theory. Updating... 

> **Martingale**: A sequence of random variables (i.e., a [stochastic process](#stochastic-process)) for which, at a particular time, the conditional expectation of the next value in the sequence is equal to the present value, regardless of all prior values.

## Background

Originally, martingale referred to a class of betting strategies that was popular in 18th-century France. The simplest of these strategies was designed for a game in which the gambler wins their stake if a coin comes up heads and loses it if the coin comes up tails. The strategy had the gambler double their bet after every loss so that the first win would recover all previous losses plus win a profit equal to the original stake. As the gambler's wealth and available time jointly approach infinity, their probability of eventually flipping heads approaches 1, which makes the martingale betting strategy seem like a sure thing. However, the exponential growth of the bets eventually bankrupts its users due to finite bankrolls. *Stopped Brownian motion*, which is a martingale process, can be used to model the trajectory of such games.

Part of the motivation for developing the concept of martingale was to show the impossibility of successful betting strategies in games of chance.

## Definition

A basic definition of a discrete-time martingale is a discrete-time stochastic process (i.e., a sequence of random variables) $X_1, X_2, X_3, \ \dots$ that satisfies for any time $n$,

$$
E(\vert X_n\vert) < \infty \\
E(X_{n+1} \mid X_1, \dots, X_n) = X_n
$$

That is, the conditional expected value of the next observation, given all the past observations, is equal to the most recent observation.

### Martingale Sequences w.r.t Another Sequence

More generally, a sequence $Y_1, Y_2, Y_3, \ \dots$ is said to be a martingale w.r.t. another sequence $X_1, X_2, X_3, \ \dots$ if for all $n$

$$
E(\vert Y_n\vert) < \infty \\
E(Y_{n+1} \mid X_1, \dots, X_n) = Y_n
$$

Similarly, a continuous-time martingale w.r.t. the stochastic process $X_t$ is a stochastic process $Y_t$ such that for all $t$ 

$$
E(\vert Y_t\vert) < \infty \\
E(Y_{t} \mid \{X_\tau, \tau\leq s\}) = Y_s \ \ \ \ \forall s\leq t
$$

This expresses the property that the conditional expectation of an observation at time $t$, given all the observations up to time $s$, is equal to the observation at time *s* (provided that $s\leq t$). Note that the second property implies that $Y_n$ is measurable w.r.t. $X_1, \dots, X_n$.

### General Definition

A stochastic process $Y:T\times \Omega \to S$ taking value in a [Banach space]($banach-space) $S$ is a martingale w.r.t. to a filtration $\Sigma_*$ and probability measure $P$ if

- $\Sigma_*$ is a filtration of the underlying probability space $(\Omega, \Sigma, P)$;
- $Y$ is adapted to the filtration, i.e., for each $t$ in the index set $T$, the random variable $Y_t$ is a $\Sigma_t$-measurable function;
- for each $t$, $Y_t$ lies in the $L^p$ space $L^1(\Omega, \Sigma_t; P, S)$, i.e., 

$$
\textbf{E}_P(\vert Y_t \vert) < +\infty
$$

- for all $s$ and $t$ with $s < t$ and all $F\in\Sigma_S$,

$$
\textbf{E}_P([Y_t-Y_s]_{\mathcal{X}_F}) = 0 \text{ or } Y_s=\textbf{E}_P(Y_t\mid \Sigma_s)
$$

​		where $\mathcal{X}_F$ denotes the indicator function of the event $F$.

It is important to note that the property of being a martingale involves both the filtration *and* the probability measure (with respect to which the expectations are taken). It is possible that *Y* could be a martingale with respect to one measure but not another one; the [Girsanov theorem](https://en.wikipedia.org/wiki/Girsanov_theorem) offers a way to find a measure with respect to which an [Itō process](https://en.wikipedia.org/wiki/Itō_process) is a martingale.

### Stochastic Process

A stochastic process is defined as a collection of random variables defined on a common probability space $(\Omega, \mathcal{F}, P)$, where $\Omega$ is a sample space, $\mathcal{F}$ is a $\sigma$-algebra, and $P$ is a probability measure; and the random variables, indexed by some set $T$, all take values in the same mathematical space $S$, which must be measurable w.r.t some $\sigma$-algebra $\Sigma$. 

In other words, for a given probability space $(\Omega, \mathcal{F}, P)$ and a measurable space $(S, \Sigma)$, a stochastic process is a collection of $S$-valued random variables, which can be written as 

$$
\{ X(t, \omega):t\in T \}
$$



