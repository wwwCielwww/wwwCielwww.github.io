{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cluster-GCN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbt99p16Ok3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0069ca-0b68-429b-9aa7-0afacbef368b"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.7)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (5.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwCuFXBbO2Iw"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import ModuleList\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import ClusterData, ClusterLoader, NeighborSampler\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.nn import SAGEConv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh69t641PF6N",
        "outputId": "f4fe6508-d5b6-4fca-ffe6-645bc0a97a2d"
      },
      "source": [
        "dataset = Planetoid(root=\"data/Planetoid\", name=\"Cora\", transform=NormalizeFeatures())\n",
        "data = dataset[0]\n",
        "\n",
        "cluster_data = ClusterData(data, num_parts=200, recursive=False,\n",
        "                           save_dir=dataset.processed_dir)\n",
        "train_loader = ClusterLoader(cluster_data, batch_size=5, shuffle=True,\n",
        "                             num_workers=12)\n",
        "\n",
        "subgraph_loader = NeighborSampler(data.edge_index, sizes=[-1], batch_size=128,\n",
        "                                  shuffle=False, num_workers=12)\n",
        "\n",
        "cluster_data, train_loader, subgraph_loader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(ClusterData(\n",
              "   data=Data(adj=[2708, 2708, nnz=10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708]),\n",
              "   num_parts=200\n",
              " ),\n",
              " <torch_geometric.data.cluster.ClusterLoader at 0x7feb68ac0f10>,\n",
              " NeighborSampler(sizes=[-1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2gH-ic0PP4b"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.convs = ModuleList(\n",
        "            [SAGEConv(in_channels, 128),\n",
        "             SAGEConv(128, out_channels)]\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, edge_index):\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i != len(self.convs) - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, 0.5, self.training)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * len(self.convs))\n",
        "        pbar.set_description(\"Evaluating...\")\n",
        "\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in subgraph_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = conv((x, x_target), edge_index)\n",
        "                if i != len(self.convs) - 1:\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x.cpu())\n",
        "\n",
        "                pbar.update(batch_size)\n",
        "\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        return x_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd_M1xCmLoaJ"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net(dataset.num_features, dataset.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enYfJk3ELydO"
      },
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss = total_nodes = 0\n",
        "    for batch in train_loader:\n",
        "        nodes = batch.train_mask.sum().item()\n",
        "        if nodes == 0:\n",
        "            continue\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = F.nll_loss(out[batch.train_mask], batch.y[batch.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * nodes\n",
        "        total_nodes += nodes\n",
        "        \n",
        "    return total_loss / total_nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBTMyN83NKsq"
      },
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "\n",
        "    out = model.inference(data.x)\n",
        "    y_pred = out.argmax(dim=-1)\n",
        "\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        correct = y_pred[mask].eq(data.y[mask]).sum().item()\n",
        "        accs.append(correct / mask.sum().item())\n",
        "        \n",
        "    return accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7LGCBeZN42G",
        "outputId": "6199a559-027a-4e92-f740-652a3fdc8d19"
      },
      "source": [
        "for epoch in range(10):\n",
        "    loss = train()\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        train_acc, val_acc, test_acc = test()\n",
        "        print()\n",
        "        print(f\"Epoch {epoch + 1} Loss {loss:.6f}\")\n",
        "        print(f\"Train Acc {train_acc:.4f} Val Acc {val_acc:.4f} Test {test_acc:.4f}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch + 1} Loss {loss:.6f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.003247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating...: 100%|██████████| 5416/5416 [00:01<00:00, 3687.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Loss 0.002976\n",
            "Train Acc 1.0000 Val Acc 0.7400 Test 0.7430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 Loss 0.004575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating...: 100%|██████████| 5416/5416 [00:01<00:00, 3693.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Loss 0.002680\n",
            "Train Acc 1.0000 Val Acc 0.7320 Test 0.7510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 Loss 0.001561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating...: 100%|██████████| 5416/5416 [00:01<00:00, 3707.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Loss 0.002849\n",
            "Train Acc 1.0000 Val Acc 0.7320 Test 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 Loss 0.001750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating...: 100%|██████████| 5416/5416 [00:01<00:00, 3647.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 Loss 0.002605\n",
            "Train Acc 1.0000 Val Acc 0.7340 Test 0.7450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 Loss 0.003195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating...: 100%|██████████| 5416/5416 [00:01<00:00, 3720.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 Loss 0.007478\n",
            "Train Acc 1.0000 Val Acc 0.7460 Test 0.7540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}